2025-03-31 19:45:15 - #----------Config info----------#
2025-03-31 19:45:15 - network: 3munet,
2025-03-31 19:45:15 - model_config: {'num_classes': 7, 'input_channels': 3, 'depths': [2, 2, 2, 2, 2], 'depths_decoder': [2, 2, 2, 2, 1], 'drop_path_rate': 0.2, 'load_ckpt_path': './pre_trained_weights/vmamba_small_e238_ema.pth'},
2025-03-31 19:45:15 - start_epoch_best_model_saving: 0,
2025-03-31 19:45:15 - condition_hd95: 9.0,
2025-03-31 19:45:15 - deep_supervision: False,
2025-03-31 19:45:15 - deep_supervision_weight: [1.0, 1.0, 1.0, 1.0, 1.0],
2025-03-31 19:45:15 - mask_update: False,
2025-03-31 19:45:15 - mfe_enable: True,
2025-03-31 19:45:15 - mcsa_enable: True,
2025-03-31 19:45:15 - datasets: vofo,
2025-03-31 19:45:15 - data_path: ./data/vofo/,
2025-03-31 19:45:15 - pretrained_path: ./pre_trained/,
2025-03-31 19:45:15 - num_classes: 7,
2025-03-31 19:45:15 - color_palette: {0: [0, 0, 0], 1: [255, 0, 0], 2: [255, 165, 0], 3: [255, 255, 0], 4: [0, 255, 0], 5: [0, 0, 255], 6: [148, 0, 211]},
2025-03-31 19:45:15 - opacity: 0.7,
2025-03-31 19:45:15 - input_size_h: 256,
2025-03-31 19:45:15 - input_size_w: 256,
2025-03-31 19:45:15 - input_channels: 3,
2025-03-31 19:45:15 - distributed: False,
2025-03-31 19:45:15 - local_rank: -1,
2025-03-31 19:45:15 - num_workers: 16,
2025-03-31 19:45:15 - seed: 42,
2025-03-31 19:45:15 - world_size: None,
2025-03-31 19:45:15 - rank: None,
2025-03-31 19:45:15 - amp: False,
2025-03-31 19:45:15 - gpu_id: 0,
2025-03-31 19:45:15 - batch_size: 16,
2025-03-31 19:45:15 - epochs: 200,
2025-03-31 19:45:15 - loss_weight: [1, 1],
2025-03-31 19:45:15 - criterion: CeDiceLoss(
  (celoss): CrossEntropyLoss()
  (diceloss): nDiceLoss()
),
2025-03-31 19:45:15 - work_dir: ./results_vofo/,
2025-03-31 19:45:15 - print_interval: 64,
2025-03-31 19:45:15 - val_interval: 30,
2025-03-31 19:45:15 - save_interval: 100,
2025-03-31 19:45:15 - threshold: 0.5,
2025-03-31 19:45:15 - train_transformer: Compose(
    <utils.myNormalize object at 0x7f0de746b490>
    <utils.myToTensor object at 0x7f0de746b4f0>
    <utils.myRandomHorizontalFlip object at 0x7f0de746b520>
    <utils.myRandomVerticalFlip object at 0x7f0de746b580>
    <utils.myRandomRotation object at 0x7f0de746b5e0>
    <utils.myResize object at 0x7f0de746b640>
),
2025-03-31 19:45:15 - test_transformer: Compose(
    <utils.myNormalize object at 0x7f0de746b730>
    <utils.myToTensor object at 0x7f0de746b790>
    <utils.myResize object at 0x7f0de746b7c0>
),
2025-03-31 19:45:15 - opt: AdamW,
2025-03-31 19:45:15 - lr: 0.0005,
2025-03-31 19:45:15 - betas: (0.9, 0.999),
2025-03-31 19:45:15 - eps: 1e-08,
2025-03-31 19:45:15 - weight_decay: 0.01,
2025-03-31 19:45:15 - amsgrad: False,
2025-03-31 19:45:15 - sch: CosineAnnealingLR,
2025-03-31 19:45:15 - T_max: 33,
2025-03-31 19:45:15 - eta_min: 1e-05,
2025-03-31 19:45:15 - last_epoch: -1,
2025-03-31 19:45:19 - flops: 3.921238656, params: 22.077297, Total params: : 27.9154
2025-03-31 19:45:26 - train: epoch 1, iter:0, loss: 3.1188, lr: 0.0005
2025-03-31 19:46:40 - train: epoch 1, iter:64, loss: 1.3981, lr: 0.0005
2025-03-31 19:47:05 - train: epoch 2, iter:0, loss: 1.3780, lr: 0.0004988906210304057
2025-03-31 19:48:21 - train: epoch 2, iter:64, loss: 1.2907, lr: 0.0004988906210304057
2025-03-31 19:48:45 - train: epoch 3, iter:0, loss: 1.2767, lr: 0.0004955725308293631
2025-03-31 19:50:01 - train: epoch 3, iter:64, loss: 1.2799, lr: 0.0004955725308293631
2025-03-31 19:50:24 - train: epoch 4, iter:0, loss: 1.2357, lr: 0.0004900757785355519
2025-03-31 19:51:41 - train: epoch 4, iter:64, loss: 1.2711, lr: 0.0004900757785355519
2025-03-31 19:52:04 - train: epoch 5, iter:0, loss: 1.2140, lr: 0.00048245014358893777
2025-03-31 19:53:20 - train: epoch 5, iter:64, loss: 1.2650, lr: 0.00048245014358893777
2025-03-31 19:53:44 - train: epoch 6, iter:0, loss: 1.2808, lr: 0.00047276468492045626
2025-03-31 19:55:00 - train: epoch 6, iter:64, loss: 1.2582, lr: 0.00047276468492045626
2025-03-31 19:55:22 - train: epoch 7, iter:0, loss: 1.2262, lr: 0.00046110711554363937
2025-03-31 19:56:39 - train: epoch 7, iter:64, loss: 1.2518, lr: 0.00046110711554363937
2025-03-31 19:57:01 - train: epoch 8, iter:0, loss: 1.2260, lr: 0.0004475830082119829
2025-03-31 19:58:17 - train: epoch 8, iter:64, loss: 1.2333, lr: 0.0004475830082119829
2025-03-31 19:58:41 - train: epoch 9, iter:0, loss: 1.3690, lr: 0.0004323148393357421
2025-03-31 19:59:57 - train: epoch 9, iter:64, loss: 1.2281, lr: 0.0004323148393357421
2025-03-31 20:00:29 - train: epoch 10, iter:0, loss: 1.1140, lr: 0.00041544087981659484
2025-03-31 20:01:45 - train: epoch 10, iter:64, loss: 1.2071, lr: 0.00041544087981659484
2025-03-31 20:02:18 - train: epoch 11, iter:0, loss: 1.1626, lr: 0.00039711394284494355
2025-03-31 20:03:34 - train: epoch 11, iter:64, loss: 1.1811, lr: 0.00039711394284494355
2025-03-31 20:04:06 - train: epoch 12, iter:0, loss: 1.1473, lr: 0.0003775
2025-03-31 20:05:21 - train: epoch 12, iter:64, loss: 1.1649, lr: 0.0003775
2025-03-31 20:05:54 - train: epoch 13, iter:0, loss: 1.0415, lr: 0.0003567766781854622
2025-03-31 20:07:10 - train: epoch 13, iter:64, loss: 1.1213, lr: 0.0003567766781854622
2025-03-31 20:07:43 - train: epoch 14, iter:0, loss: 1.1443, lr: 0.0003351316510127683
2025-03-31 20:08:59 - train: epoch 14, iter:64, loss: 1.1044, lr: 0.0003351316510127683
2025-03-31 20:09:41 - train: epoch 15, iter:0, loss: 1.1799, lr: 0.0003127609391998097
2025-03-31 20:10:57 - train: epoch 15, iter:64, loss: 1.0498, lr: 0.0003127609391998097
2025-03-31 20:11:38 - train: epoch 16, iter:0, loss: 0.9465, lr: 0.0002898671353769549
2025-03-31 20:12:54 - train: epoch 16, iter:64, loss: 1.0269, lr: 0.0002898671353769549
2025-03-31 20:13:34 - train: epoch 17, iter:0, loss: 1.0886, lr: 0.0002666575693768169
2025-03-31 20:14:50 - train: epoch 17, iter:64, loss: 0.9927, lr: 0.0002666575693768169
2025-03-31 20:15:31 - train: epoch 18, iter:0, loss: 1.0866, lr: 0.00024334243062318312
2025-03-31 20:16:47 - train: epoch 18, iter:64, loss: 0.9645, lr: 0.00024334243062318312
2025-03-31 20:17:24 - train: epoch 19, iter:0, loss: 1.0087, lr: 0.00022013286462304514
2025-03-31 20:18:40 - train: epoch 19, iter:64, loss: 0.9456, lr: 0.00022013286462304514
2025-03-31 20:19:25 - train: epoch 20, iter:0, loss: 0.9402, lr: 0.0001972390608001904
2025-03-31 20:20:41 - train: epoch 20, iter:64, loss: 0.9249, lr: 0.0001972390608001904
2025-03-31 20:21:27 - train: epoch 21, iter:0, loss: 0.9485, lr: 0.0001748683489872317
2025-03-31 20:22:43 - train: epoch 21, iter:64, loss: 0.8901, lr: 0.0001748683489872317
2025-03-31 20:23:28 - train: epoch 22, iter:0, loss: 0.9456, lr: 0.0001532233218145378
2025-03-31 20:24:43 - train: epoch 22, iter:64, loss: 0.8723, lr: 0.0001532233218145378
2025-03-31 20:25:30 - train: epoch 23, iter:0, loss: 0.8770, lr: 0.00013250000000000005
2025-03-31 20:26:46 - train: epoch 23, iter:64, loss: 0.8542, lr: 0.00013250000000000005
2025-03-31 20:27:32 - train: epoch 24, iter:0, loss: 1.0333, lr: 0.00011288605715505647
2025-03-31 20:28:48 - train: epoch 24, iter:64, loss: 0.8396, lr: 0.00011288605715505647
2025-03-31 20:29:34 - train: epoch 25, iter:0, loss: 0.7594, lr: 9.455912018340518e-05
2025-03-31 20:30:50 - train: epoch 25, iter:64, loss: 0.8202, lr: 9.455912018340518e-05
2025-03-31 20:31:38 - train: epoch 26, iter:0, loss: 0.8980, lr: 7.76851606642578e-05
2025-03-31 20:32:53 - train: epoch 26, iter:64, loss: 0.8146, lr: 7.76851606642578e-05
2025-03-31 20:33:37 - train: epoch 27, iter:0, loss: 0.7338, lr: 6.241699178801706e-05
2025-03-31 20:34:53 - train: epoch 27, iter:64, loss: 0.8134, lr: 6.241699178801706e-05
2025-03-31 20:35:39 - train: epoch 28, iter:0, loss: 0.7624, lr: 4.8892884456360634e-05
2025-03-31 20:36:55 - train: epoch 28, iter:64, loss: 0.8070, lr: 4.8892884456360634e-05
2025-03-31 20:37:42 - train: epoch 29, iter:0, loss: 0.7093, lr: 3.723531507954378e-05
2025-03-31 20:38:58 - train: epoch 29, iter:64, loss: 0.7894, lr: 3.723531507954378e-05
2025-03-31 20:39:45 - train: epoch 30, iter:0, loss: 0.8435, lr: 2.7549856411062228e-05
2025-03-31 20:41:01 - train: epoch 30, iter:64, loss: 0.7820, lr: 2.7549856411062228e-05
2025-03-31 20:41:45 - train: epoch 31, iter:0, loss: 0.8190, lr: 1.9924221464448178e-05
2025-03-31 20:43:01 - train: epoch 31, iter:64, loss: 0.7746, lr: 1.9924221464448178e-05
2025-03-31 20:43:47 - train: epoch 32, iter:0, loss: 0.7896, lr: 1.4427469170636887e-05
2025-03-31 20:45:03 - train: epoch 32, iter:64, loss: 0.7656, lr: 1.4427469170636887e-05
2025-03-31 20:45:49 - train: epoch 33, iter:0, loss: 0.7710, lr: 1.1109378969594277e-05
2025-03-31 20:47:04 - train: epoch 33, iter:64, loss: 0.7749, lr: 1.1109378969594277e-05
2025-03-31 20:47:52 - train: epoch 34, iter:0, loss: 0.8227, lr: 1e-05
2025-03-31 20:49:08 - train: epoch 34, iter:64, loss: 0.7587, lr: 1e-05
2025-03-31 20:49:54 - train: epoch 35, iter:0, loss: 0.7147, lr: 1.1109378969594277e-05
2025-03-31 20:51:10 - train: epoch 35, iter:64, loss: 0.7689, lr: 1.1109378969594277e-05
2025-03-31 20:52:00 - train: epoch 36, iter:0, loss: 0.8047, lr: 1.442746917063683e-05
2025-03-31 20:53:16 - train: epoch 36, iter:64, loss: 0.7638, lr: 1.442746917063683e-05
2025-03-31 20:54:04 - train: epoch 37, iter:0, loss: 0.8309, lr: 1.992422146444812e-05
2025-03-31 20:55:20 - train: epoch 37, iter:64, loss: 0.7705, lr: 1.992422146444812e-05
2025-03-31 20:56:04 - train: epoch 38, iter:0, loss: 0.7619, lr: 2.75498564110622e-05
2025-03-31 20:57:20 - train: epoch 38, iter:64, loss: 0.7585, lr: 2.75498564110622e-05
2025-03-31 20:58:06 - train: epoch 39, iter:0, loss: 0.9092, lr: 3.7235315079543705e-05
2025-03-31 20:59:22 - train: epoch 39, iter:64, loss: 0.7619, lr: 3.7235315079543705e-05
2025-03-31 21:00:09 - train: epoch 40, iter:0, loss: 0.7341, lr: 4.8892884456360566e-05
2025-03-31 21:01:24 - train: epoch 40, iter:64, loss: 0.7592, lr: 4.8892884456360566e-05
2025-03-31 21:02:10 - train: epoch 41, iter:0, loss: 0.7029, lr: 6.24169917880171e-05
2025-03-31 21:03:26 - train: epoch 41, iter:64, loss: 0.7514, lr: 6.24169917880171e-05
2025-03-31 21:04:11 - train: epoch 42, iter:0, loss: 0.6908, lr: 7.768516066425779e-05
2025-03-31 21:05:27 - train: epoch 42, iter:64, loss: 0.7639, lr: 7.768516066425779e-05
2025-03-31 21:06:14 - train: epoch 43, iter:0, loss: 0.7770, lr: 9.455912018340522e-05
2025-03-31 21:07:30 - train: epoch 43, iter:64, loss: 0.7539, lr: 9.455912018340522e-05
2025-03-31 21:08:17 - train: epoch 44, iter:0, loss: 0.7522, lr: 0.00011288605715505645
2025-03-31 21:09:33 - train: epoch 44, iter:64, loss: 0.7740, lr: 0.00011288605715505645
2025-03-31 21:10:22 - train: epoch 45, iter:0, loss: 0.8804, lr: 0.00013249999999999991
2025-03-31 21:11:37 - train: epoch 45, iter:64, loss: 0.7538, lr: 0.00013249999999999991
2025-03-31 21:12:26 - train: epoch 46, iter:0, loss: 0.7213, lr: 0.00015322332181453787
2025-03-31 21:13:42 - train: epoch 46, iter:64, loss: 0.7693, lr: 0.00015322332181453787
2025-03-31 21:14:30 - train: epoch 47, iter:0, loss: 0.8702, lr: 0.00017486834898723167
2025-03-31 21:15:46 - train: epoch 47, iter:64, loss: 0.7567, lr: 0.00017486834898723167
2025-03-31 21:16:33 - train: epoch 48, iter:0, loss: 0.7484, lr: 0.00019723906080019042
2025-03-31 21:17:49 - train: epoch 48, iter:64, loss: 0.7742, lr: 0.00019723906080019042
2025-03-31 21:18:35 - train: epoch 49, iter:0, loss: 0.7413, lr: 0.00022013286462304512
2025-03-31 21:19:51 - train: epoch 49, iter:64, loss: 0.7777, lr: 0.00022013286462304512
2025-03-31 21:20:39 - train: epoch 50, iter:0, loss: 0.7202, lr: 0.00024334243062318304
2025-03-31 21:21:54 - train: epoch 50, iter:64, loss: 0.7677, lr: 0.00024334243062318304
2025-03-31 21:22:39 - train: epoch 51, iter:0, loss: 0.6814, lr: 0.0002666575693768169
2025-03-31 21:23:55 - train: epoch 51, iter:64, loss: 0.7372, lr: 0.0002666575693768169
2025-03-31 21:24:41 - train: epoch 52, iter:0, loss: 0.7366, lr: 0.00028986713537695484
2025-03-31 21:25:57 - train: epoch 52, iter:64, loss: 0.7504, lr: 0.00028986713537695484
2025-03-31 21:26:49 - train: epoch 53, iter:0, loss: 0.6386, lr: 0.00031276093919980976
2025-03-31 21:28:04 - train: epoch 53, iter:64, loss: 0.7524, lr: 0.00031276093919980976
2025-03-31 21:28:57 - train: epoch 54, iter:0, loss: 0.6982, lr: 0.00033513165101276834
2025-03-31 21:30:13 - train: epoch 54, iter:64, loss: 0.7576, lr: 0.00033513165101276834
2025-03-31 21:30:59 - train: epoch 55, iter:0, loss: 0.6631, lr: 0.0003567766781854621
2025-03-31 21:32:15 - train: epoch 55, iter:64, loss: 0.7339, lr: 0.0003567766781854621
2025-03-31 21:33:00 - train: epoch 56, iter:0, loss: 0.5672, lr: 0.0003775
2025-03-31 21:34:16 - train: epoch 56, iter:64, loss: 0.7505, lr: 0.0003775
2025-03-31 21:35:04 - train: epoch 57, iter:0, loss: 0.6596, lr: 0.00039711394284494344
2025-03-31 21:36:19 - train: epoch 57, iter:64, loss: 0.7468, lr: 0.00039711394284494344
2025-03-31 21:37:02 - train: epoch 58, iter:0, loss: 0.7751, lr: 0.00041544087981659473
2025-03-31 21:38:17 - train: epoch 58, iter:64, loss: 0.7306, lr: 0.00041544087981659473
2025-03-31 21:39:01 - train: epoch 59, iter:0, loss: 0.7925, lr: 0.0004323148393357422
2025-03-31 21:40:17 - train: epoch 59, iter:64, loss: 0.7510, lr: 0.0004323148393357422
2025-03-31 21:41:03 - train: epoch 60, iter:0, loss: 0.6918, lr: 0.0004475830082119829
2025-03-31 21:42:19 - train: epoch 60, iter:64, loss: 0.7469, lr: 0.0004475830082119829
2025-03-31 21:43:02 - train: epoch 61, iter:0, loss: 0.7498, lr: 0.0004611071155436393
2025-03-31 21:44:18 - train: epoch 61, iter:64, loss: 0.7277, lr: 0.0004611071155436393
2025-03-31 21:45:00 - train: epoch 62, iter:0, loss: 0.6917, lr: 0.0004727646849204562
2025-03-31 21:46:17 - train: epoch 62, iter:64, loss: 0.7038, lr: 0.0004727646849204562
2025-03-31 21:47:06 - train: epoch 63, iter:0, loss: 0.6253, lr: 0.0004824501435889377
2025-03-31 21:48:22 - train: epoch 63, iter:64, loss: 0.7055, lr: 0.0004824501435889377
2025-03-31 21:49:10 - train: epoch 64, iter:0, loss: 0.5219, lr: 0.0004900757785355519
2025-03-31 21:50:26 - train: epoch 64, iter:64, loss: 0.6874, lr: 0.0004900757785355519
2025-03-31 21:51:11 - train: epoch 65, iter:0, loss: 0.6157, lr: 0.0004955725308293631
2025-03-31 21:52:28 - train: epoch 65, iter:64, loss: 0.6870, lr: 0.0004955725308293631
2025-03-31 21:53:16 - train: epoch 66, iter:0, loss: 0.4697, lr: 0.0004988906210304056
2025-03-31 21:54:32 - train: epoch 66, iter:64, loss: 0.6674, lr: 0.0004988906210304056
2025-03-31 21:55:20 - train: epoch 67, iter:0, loss: 0.7926, lr: 0.0004999999999999999
2025-03-31 21:56:35 - train: epoch 67, iter:64, loss: 0.6814, lr: 0.0004999999999999999
2025-03-31 21:57:19 - train: epoch 68, iter:0, loss: 0.5881, lr: 0.0004988906210304057
2025-03-31 21:58:35 - train: epoch 68, iter:64, loss: 0.6779, lr: 0.0004988906210304057
2025-03-31 21:59:23 - train: epoch 69, iter:0, loss: 0.5219, lr: 0.000495572530829363
2025-03-31 22:00:39 - train: epoch 69, iter:64, loss: 0.6711, lr: 0.000495572530829363
2025-03-31 22:01:23 - train: epoch 70, iter:0, loss: 0.6851, lr: 0.0004900757785355518
2025-03-31 22:02:39 - train: epoch 70, iter:64, loss: 0.6539, lr: 0.0004900757785355518
2025-03-31 22:03:29 - train: epoch 71, iter:0, loss: 0.6293, lr: 0.00048245014358893777
2025-03-31 22:04:45 - train: epoch 71, iter:64, loss: 0.6422, lr: 0.00048245014358893777
2025-03-31 22:05:33 - train: epoch 72, iter:0, loss: 0.6060, lr: 0.0004727646849204562
2025-03-31 22:06:48 - train: epoch 72, iter:64, loss: 0.6305, lr: 0.0004727646849204562
2025-03-31 22:07:36 - train: epoch 73, iter:0, loss: 0.5612, lr: 0.0004611071155436393
2025-03-31 22:08:51 - train: epoch 73, iter:64, loss: 0.6452, lr: 0.0004611071155436393
2025-03-31 22:09:40 - train: epoch 74, iter:0, loss: 0.6457, lr: 0.00044758300821198295
2025-03-31 22:10:56 - train: epoch 74, iter:64, loss: 0.6121, lr: 0.00044758300821198295
2025-03-31 22:11:43 - train: epoch 75, iter:0, loss: 0.6000, lr: 0.0004323148393357421
2025-03-31 22:12:59 - train: epoch 75, iter:64, loss: 0.6254, lr: 0.0004323148393357421
2025-03-31 22:13:43 - train: epoch 76, iter:0, loss: 0.4928, lr: 0.00041544087981659484
2025-03-31 22:14:59 - train: epoch 76, iter:64, loss: 0.5895, lr: 0.00041544087981659484
2025-03-31 22:15:46 - train: epoch 77, iter:0, loss: 0.4674, lr: 0.00039711394284494366
2025-03-31 22:17:02 - train: epoch 77, iter:64, loss: 0.5902, lr: 0.00039711394284494366
2025-03-31 22:17:51 - train: epoch 78, iter:0, loss: 0.4901, lr: 0.00037749999999999996
2025-03-31 22:19:07 - train: epoch 78, iter:64, loss: 0.5830, lr: 0.00037749999999999996
2025-03-31 22:19:58 - train: epoch 79, iter:0, loss: 0.4960, lr: 0.0003567766781854622
2025-03-31 22:21:14 - train: epoch 79, iter:64, loss: 0.5597, lr: 0.0003567766781854622
2025-03-31 22:22:02 - train: epoch 80, iter:0, loss: 0.5228, lr: 0.0003351316510127683
2025-03-31 22:23:18 - train: epoch 80, iter:64, loss: 0.5467, lr: 0.0003351316510127683
2025-03-31 22:24:05 - train: epoch 81, iter:0, loss: 0.5211, lr: 0.00031276093919980954
2025-03-31 22:25:21 - train: epoch 81, iter:64, loss: 0.5504, lr: 0.00031276093919980954
2025-03-31 22:26:10 - train: epoch 82, iter:0, loss: 0.5216, lr: 0.0002898671353769548
2025-03-31 22:27:25 - train: epoch 82, iter:64, loss: 0.5409, lr: 0.0002898671353769548
2025-03-31 22:28:15 - train: epoch 83, iter:0, loss: 0.5750, lr: 0.0002666575693768169
2025-03-31 22:29:31 - train: epoch 83, iter:64, loss: 0.5276, lr: 0.0002666575693768169
2025-03-31 22:30:21 - train: epoch 84, iter:0, loss: 0.6084, lr: 0.0002433424306231828
2025-03-31 22:31:36 - train: epoch 84, iter:64, loss: 0.5099, lr: 0.0002433424306231828
2025-03-31 22:32:25 - train: epoch 85, iter:0, loss: 0.5395, lr: 0.00022013286462304493
2025-03-31 22:33:41 - train: epoch 85, iter:64, loss: 0.4967, lr: 0.00022013286462304493
2025-03-31 22:34:29 - train: epoch 86, iter:0, loss: 0.4947, lr: 0.00019723906080019042
2025-03-31 22:35:45 - train: epoch 86, iter:64, loss: 0.4869, lr: 0.00019723906080019042
2025-03-31 22:36:35 - train: epoch 87, iter:0, loss: 0.4979, lr: 0.00017486834898723167
2025-03-31 22:37:50 - train: epoch 87, iter:64, loss: 0.4955, lr: 0.00017486834898723167
2025-03-31 22:38:41 - train: epoch 88, iter:0, loss: 0.4750, lr: 0.00015322332181453806
2025-03-31 22:39:57 - train: epoch 88, iter:64, loss: 0.4657, lr: 0.00015322332181453806
2025-03-31 22:40:46 - train: epoch 89, iter:0, loss: 0.4571, lr: 0.0001325000000000001
2025-03-31 22:42:02 - train: epoch 89, iter:64, loss: 0.4773, lr: 0.0001325000000000001
2025-03-31 22:42:51 - train: epoch 90, iter:0, loss: 0.3443, lr: 0.00011288605715505646
2025-03-31 22:44:07 - train: epoch 90, iter:64, loss: 0.4690, lr: 0.00011288605715505646
2025-03-31 22:44:55 - train: epoch 91, iter:0, loss: 0.5209, lr: 9.455912018340506e-05
2025-03-31 22:46:11 - train: epoch 91, iter:64, loss: 0.4662, lr: 9.455912018340506e-05
2025-03-31 22:46:59 - train: epoch 92, iter:0, loss: 0.4421, lr: 7.768516066425794e-05
2025-03-31 22:48:14 - train: epoch 92, iter:64, loss: 0.4501, lr: 7.768516066425794e-05
2025-03-31 22:49:05 - train: epoch 93, iter:0, loss: 0.5388, lr: 6.24169917880171e-05
2025-03-31 22:50:21 - train: epoch 93, iter:64, loss: 0.4655, lr: 6.24169917880171e-05
2025-03-31 22:51:10 - train: epoch 94, iter:0, loss: 0.4672, lr: 4.8892884456360824e-05
2025-03-31 22:52:26 - train: epoch 94, iter:64, loss: 0.4428, lr: 4.8892884456360824e-05
2025-03-31 22:53:14 - train: epoch 95, iter:0, loss: 0.3588, lr: 3.723531507954368e-05
2025-03-31 22:54:30 - train: epoch 95, iter:64, loss: 0.4441, lr: 3.723531507954368e-05
2025-03-31 22:55:20 - train: epoch 96, iter:0, loss: 0.5116, lr: 2.754985641106227e-05
2025-03-31 22:56:36 - train: epoch 96, iter:64, loss: 0.4448, lr: 2.754985641106227e-05
2025-03-31 22:57:24 - train: epoch 97, iter:0, loss: 0.4332, lr: 1.992422146444814e-05
2025-03-31 22:58:40 - train: epoch 97, iter:64, loss: 0.4356, lr: 1.992422146444814e-05
2025-03-31 22:59:31 - train: epoch 98, iter:0, loss: 0.4323, lr: 1.4427469170636938e-05
2025-03-31 23:00:46 - train: epoch 98, iter:64, loss: 0.4313, lr: 1.4427469170636938e-05
2025-03-31 23:01:36 - train: epoch 99, iter:0, loss: 0.4627, lr: 1.1109378969594304e-05
2025-03-31 23:02:52 - train: epoch 99, iter:64, loss: 0.4359, lr: 1.1109378969594304e-05
2025-03-31 23:03:42 - train: epoch 100, iter:0, loss: 0.4679, lr: 1e-05
2025-03-31 23:04:58 - train: epoch 100, iter:64, loss: 0.4256, lr: 1e-05
2025-03-31 23:05:48 - train: epoch 101, iter:0, loss: 0.3299, lr: 1.1109378969594277e-05
2025-03-31 23:07:04 - train: epoch 101, iter:64, loss: 0.4337, lr: 1.1109378969594277e-05
2025-03-31 23:07:54 - train: epoch 102, iter:0, loss: 0.4942, lr: 1.4427469170636805e-05
2025-03-31 23:09:10 - train: epoch 102, iter:64, loss: 0.4287, lr: 1.4427469170636805e-05
2025-03-31 23:09:57 - train: epoch 103, iter:0, loss: 0.4857, lr: 1.9924221464448096e-05
2025-03-31 23:11:13 - train: epoch 103, iter:64, loss: 0.4253, lr: 1.9924221464448096e-05
2025-03-31 23:12:04 - train: epoch 104, iter:0, loss: 0.4510, lr: 2.7549856411062065e-05
2025-03-31 23:13:20 - train: epoch 104, iter:64, loss: 0.4332, lr: 2.7549856411062065e-05
2025-03-31 23:14:08 - train: epoch 105, iter:0, loss: 0.3961, lr: 3.7235315079543814e-05
2025-03-31 23:15:24 - train: epoch 105, iter:64, loss: 0.4186, lr: 3.7235315079543814e-05
2025-03-31 23:16:11 - train: epoch 106, iter:0, loss: 0.3744, lr: 4.889288445636054e-05
2025-03-31 23:17:27 - train: epoch 106, iter:64, loss: 0.4260, lr: 4.889288445636054e-05
2025-03-31 23:18:16 - train: epoch 107, iter:0, loss: 0.4098, lr: 6.241699178801706e-05
2025-03-31 23:19:31 - train: epoch 107, iter:64, loss: 0.4321, lr: 6.241699178801706e-05
2025-03-31 23:20:21 - train: epoch 108, iter:0, loss: 0.3599, lr: 7.768516066425791e-05
2025-03-31 23:21:37 - train: epoch 108, iter:64, loss: 0.4369, lr: 7.768516066425791e-05
2025-03-31 23:22:24 - train: epoch 109, iter:0, loss: 0.3885, lr: 9.455912018340503e-05
2025-03-31 23:23:40 - train: epoch 109, iter:64, loss: 0.4227, lr: 9.455912018340503e-05
2025-03-31 23:24:29 - train: epoch 110, iter:0, loss: 0.3976, lr: 0.00011288605715505642
2025-03-31 23:25:45 - train: epoch 110, iter:64, loss: 0.4272, lr: 0.00011288605715505642
2025-03-31 23:26:30 - train: epoch 111, iter:0, loss: 0.3142, lr: 0.0001325000000000001
2025-03-31 23:27:46 - train: epoch 111, iter:64, loss: 0.4520, lr: 0.0001325000000000001
2025-03-31 23:28:33 - train: epoch 112, iter:0, loss: 0.3950, lr: 0.00015322332181453806
2025-03-31 23:29:49 - train: epoch 112, iter:64, loss: 0.4427, lr: 0.00015322332181453806
2025-03-31 23:30:40 - train: epoch 113, iter:0, loss: 0.4671, lr: 0.00017486834898723167
2025-03-31 23:31:56 - train: epoch 113, iter:64, loss: 0.4348, lr: 0.00017486834898723167
2025-03-31 23:32:46 - train: epoch 114, iter:0, loss: 0.4532, lr: 0.00019723906080019042
2025-03-31 23:34:02 - train: epoch 114, iter:64, loss: 0.4432, lr: 0.00019723906080019042
2025-03-31 23:34:55 - train: epoch 115, iter:0, loss: 0.3765, lr: 0.00022013286462304493
2025-03-31 23:36:11 - train: epoch 115, iter:64, loss: 0.4565, lr: 0.00022013286462304493
2025-03-31 23:36:59 - train: epoch 116, iter:0, loss: 0.4193, lr: 0.00024334243062318353
2025-03-31 23:38:15 - train: epoch 116, iter:64, loss: 0.4502, lr: 0.00024334243062318353
2025-03-31 23:39:01 - train: epoch 117, iter:0, loss: 0.4965, lr: 0.00026665756937681697
2025-03-31 23:40:17 - train: epoch 117, iter:64, loss: 0.4617, lr: 0.00026665756937681697
2025-03-31 23:41:07 - train: epoch 118, iter:0, loss: 0.5024, lr: 0.0002898671353769551
2025-03-31 23:42:23 - train: epoch 118, iter:64, loss: 0.4707, lr: 0.0002898671353769551
2025-03-31 23:43:10 - train: epoch 119, iter:0, loss: 0.4666, lr: 0.0003127609391998097
2025-03-31 23:44:26 - train: epoch 119, iter:64, loss: 0.4699, lr: 0.0003127609391998097
2025-03-31 23:45:15 - train: epoch 120, iter:0, loss: 0.4227, lr: 0.0003351316510127685
2025-03-31 23:46:32 - train: epoch 120, iter:64, loss: 0.4752, lr: 0.0003351316510127685
2025-03-31 23:47:19 - train: epoch 121, iter:0, loss: 0.5414, lr: 0.00035677667818546205
2025-03-31 23:48:34 - train: epoch 121, iter:64, loss: 0.4723, lr: 0.00035677667818546205
2025-03-31 23:49:19 - train: epoch 122, iter:0, loss: 0.4103, lr: 0.0003775000000000004
2025-03-31 23:50:35 - train: epoch 122, iter:64, loss: 0.5014, lr: 0.0003775000000000004
2025-03-31 23:51:21 - train: epoch 123, iter:0, loss: 0.5906, lr: 0.0003971139428449437
2025-03-31 23:52:37 - train: epoch 123, iter:64, loss: 0.4902, lr: 0.0003971139428449437
2025-03-31 23:53:28 - train: epoch 124, iter:0, loss: 0.5760, lr: 0.0004154408798165951
2025-03-31 23:54:43 - train: epoch 124, iter:64, loss: 0.5042, lr: 0.0004154408798165951
2025-03-31 23:55:28 - train: epoch 125, iter:0, loss: 0.5568, lr: 0.00043231483933574223
2025-03-31 23:56:45 - train: epoch 125, iter:64, loss: 0.4954, lr: 0.00043231483933574223
2025-03-31 23:57:36 - train: epoch 126, iter:0, loss: 0.5150, lr: 0.00044758300821198316
2025-03-31 23:58:52 - train: epoch 126, iter:64, loss: 0.5138, lr: 0.00044758300821198316
2025-03-31 23:59:40 - train: epoch 127, iter:0, loss: 0.5864, lr: 0.0004611071155436397
2025-04-01 00:00:56 - train: epoch 127, iter:64, loss: 0.5190, lr: 0.0004611071155436397
2025-04-01 00:01:44 - train: epoch 128, iter:0, loss: 0.4767, lr: 0.00047276468492045664
2025-04-01 00:03:00 - train: epoch 128, iter:64, loss: 0.4990, lr: 0.00047276468492045664
2025-04-01 00:03:50 - train: epoch 129, iter:0, loss: 0.4490, lr: 0.00048245014358893804
2025-04-01 00:05:05 - train: epoch 129, iter:64, loss: 0.5032, lr: 0.00048245014358893804
2025-04-01 00:05:54 - train: epoch 130, iter:0, loss: 0.5347, lr: 0.0004900757785355522
2025-04-01 00:07:10 - train: epoch 130, iter:64, loss: 0.4855, lr: 0.0004900757785355522
2025-04-01 00:07:57 - train: epoch 131, iter:0, loss: 0.4620, lr: 0.0004955725308293634
2025-04-01 00:09:13 - train: epoch 131, iter:64, loss: 0.4840, lr: 0.0004955725308293634
2025-04-01 00:10:03 - train: epoch 132, iter:0, loss: 0.4158, lr: 0.0004988906210304061
2025-04-01 00:11:20 - train: epoch 132, iter:64, loss: 0.4890, lr: 0.0004988906210304061
2025-04-01 00:12:08 - train: epoch 133, iter:0, loss: 0.4079, lr: 0.0005000000000000003
2025-04-01 00:13:24 - train: epoch 133, iter:64, loss: 0.4600, lr: 0.0005000000000000003
2025-04-01 00:14:10 - train: epoch 134, iter:0, loss: 0.4399, lr: 0.000498890621030406
2025-04-01 00:15:26 - train: epoch 134, iter:64, loss: 0.4813, lr: 0.000498890621030406
2025-04-01 00:16:14 - train: epoch 135, iter:0, loss: 0.4995, lr: 0.0004955725308293635
2025-04-01 00:17:30 - train: epoch 135, iter:64, loss: 0.4743, lr: 0.0004955725308293635
2025-04-01 00:18:19 - train: epoch 136, iter:0, loss: 0.5816, lr: 0.0004900757785355522
2025-04-01 00:19:35 - train: epoch 136, iter:64, loss: 0.4560, lr: 0.0004900757785355522
2025-04-01 00:20:24 - train: epoch 137, iter:0, loss: 0.2768, lr: 0.0004824501435889381
2025-04-01 00:21:39 - train: epoch 137, iter:64, loss: 0.4664, lr: 0.0004824501435889381
2025-04-01 00:22:27 - train: epoch 138, iter:0, loss: 0.4693, lr: 0.00047276468492045653
2025-04-01 00:23:43 - train: epoch 138, iter:64, loss: 0.4690, lr: 0.00047276468492045653
2025-04-01 00:24:26 - train: epoch 139, iter:0, loss: 0.3313, lr: 0.00046110711554363986
2025-04-01 00:25:43 - train: epoch 139, iter:64, loss: 0.4577, lr: 0.00046110711554363986
2025-04-01 00:26:28 - train: epoch 140, iter:0, loss: 0.4807, lr: 0.0004475830082119833
2025-04-01 00:27:44 - train: epoch 140, iter:64, loss: 0.4585, lr: 0.0004475830082119833
2025-04-01 00:28:31 - train: epoch 141, iter:0, loss: 0.4323, lr: 0.0004323148393357428
2025-04-01 00:29:47 - train: epoch 141, iter:64, loss: 0.4276, lr: 0.0004323148393357428
2025-04-01 00:30:33 - train: epoch 142, iter:0, loss: 0.3270, lr: 0.00041544087981659533
2025-04-01 00:31:49 - train: epoch 142, iter:64, loss: 0.4281, lr: 0.00041544087981659533
2025-04-01 00:32:36 - train: epoch 143, iter:0, loss: 0.4465, lr: 0.000397113942844944
2025-04-01 00:33:51 - train: epoch 143, iter:64, loss: 0.4147, lr: 0.000397113942844944
2025-04-01 00:34:40 - train: epoch 144, iter:0, loss: 0.3350, lr: 0.0003775000000000003
2025-04-01 00:35:56 - train: epoch 144, iter:64, loss: 0.4191, lr: 0.0003775000000000003
2025-04-01 00:36:46 - train: epoch 145, iter:0, loss: 0.3391, lr: 0.0003567766781854627
2025-04-01 00:38:01 - train: epoch 145, iter:64, loss: 0.4180, lr: 0.0003567766781854627
2025-04-01 00:38:51 - train: epoch 146, iter:0, loss: 0.3807, lr: 0.0003351316510127687
2025-04-01 00:40:07 - train: epoch 146, iter:64, loss: 0.4013, lr: 0.0003351316510127687
2025-04-01 00:40:55 - train: epoch 147, iter:0, loss: 0.2887, lr: 0.0003127609391998104
2025-04-01 00:42:10 - train: epoch 147, iter:64, loss: 0.3942, lr: 0.0003127609391998104
2025-04-01 00:43:02 - train: epoch 148, iter:0, loss: 0.3629, lr: 0.000289867135376955
2025-04-01 00:44:18 - train: epoch 148, iter:64, loss: 0.3801, lr: 0.000289867135376955
2025-04-01 00:45:06 - train: epoch 149, iter:0, loss: 0.3679, lr: 0.00026665756937681724
2025-04-01 00:46:21 - train: epoch 149, iter:64, loss: 0.3868, lr: 0.00026665756937681724
2025-04-01 00:47:11 - train: epoch 150, iter:0, loss: 0.4237, lr: 0.00024334243062318334
2025-04-01 00:48:26 - train: epoch 150, iter:64, loss: 0.3927, lr: 0.00024334243062318334
2025-04-01 00:49:14 - train: epoch 151, iter:0, loss: 0.3895, lr: 0.00022013286462304563
2025-04-01 00:50:30 - train: epoch 151, iter:64, loss: 0.3714, lr: 0.00022013286462304563
2025-04-01 00:51:22 - train: epoch 152, iter:0, loss: 0.3564, lr: 0.00019723906080019066
2025-04-01 00:52:37 - train: epoch 152, iter:64, loss: 0.3683, lr: 0.00019723906080019066
2025-04-01 00:53:27 - train: epoch 153, iter:0, loss: 0.4743, lr: 0.0001748683489872323
2025-04-01 00:54:43 - train: epoch 153, iter:64, loss: 0.3534, lr: 0.0001748683489872323
2025-04-01 00:55:30 - train: epoch 154, iter:0, loss: 0.2826, lr: 0.00015322332181453787
2025-04-01 00:56:46 - train: epoch 154, iter:64, loss: 0.3477, lr: 0.00015322332181453787
2025-04-01 00:57:35 - train: epoch 155, iter:0, loss: 0.3337, lr: 0.00013250000000000032
2025-04-01 00:58:50 - train: epoch 155, iter:64, loss: 0.3457, lr: 0.00013250000000000032
2025-04-01 00:59:43 - train: epoch 156, iter:0, loss: 0.3105, lr: 0.00011288605715505662
2025-04-01 01:00:59 - train: epoch 156, iter:64, loss: 0.3398, lr: 0.00011288605715505662
2025-04-01 01:01:47 - train: epoch 157, iter:0, loss: 0.2719, lr: 9.455912018340556e-05
2025-04-01 01:03:04 - train: epoch 157, iter:64, loss: 0.3392, lr: 9.455912018340556e-05
2025-04-01 01:03:52 - train: epoch 158, iter:0, loss: 0.3681, lr: 7.768516066425809e-05
2025-04-01 01:05:08 - train: epoch 158, iter:64, loss: 0.3318, lr: 7.768516066425809e-05
2025-04-01 01:05:57 - train: epoch 159, iter:0, loss: 0.4197, lr: 6.241699178801724e-05
2025-04-01 01:07:12 - train: epoch 159, iter:64, loss: 0.3464, lr: 6.241699178801724e-05
2025-04-01 01:08:00 - train: epoch 160, iter:0, loss: 0.1982, lr: 4.889288445636069e-05
2025-04-01 01:09:16 - train: epoch 160, iter:64, loss: 0.3334, lr: 4.889288445636069e-05
2025-04-01 01:10:05 - train: epoch 161, iter:0, loss: 0.4518, lr: 3.723531507954374e-05
2025-04-01 01:11:21 - train: epoch 161, iter:64, loss: 0.3238, lr: 3.723531507954374e-05
2025-04-01 01:12:09 - train: epoch 162, iter:0, loss: 0.3040, lr: 2.7549856411062316e-05
2025-04-01 01:13:25 - train: epoch 162, iter:64, loss: 0.3206, lr: 2.7549856411062316e-05
2025-04-01 01:14:12 - train: epoch 163, iter:0, loss: 0.2595, lr: 1.992422146444818e-05
2025-04-01 01:15:28 - train: epoch 163, iter:64, loss: 0.3174, lr: 1.992422146444818e-05
2025-04-01 01:16:18 - train: epoch 164, iter:0, loss: 0.2809, lr: 1.4427469170636944e-05
2025-04-01 01:17:33 - train: epoch 164, iter:64, loss: 0.3158, lr: 1.4427469170636944e-05
2025-04-01 01:18:19 - train: epoch 165, iter:0, loss: 0.2579, lr: 1.1109378969594306e-05
2025-04-01 01:19:35 - train: epoch 165, iter:64, loss: 0.3171, lr: 1.1109378969594306e-05
2025-04-01 01:20:24 - train: epoch 166, iter:0, loss: 0.3125, lr: 1e-05
2025-04-01 01:21:41 - train: epoch 166, iter:64, loss: 0.3281, lr: 1e-05
2025-04-01 01:22:28 - train: epoch 167, iter:0, loss: 0.2671, lr: 1.1109378969594277e-05
2025-04-01 01:23:44 - train: epoch 167, iter:64, loss: 0.3216, lr: 1.1109378969594277e-05
2025-04-01 01:24:33 - train: epoch 168, iter:0, loss: 0.3963, lr: 1.4427469170636778e-05
2025-04-01 01:25:48 - train: epoch 168, iter:64, loss: 0.3185, lr: 1.4427469170636778e-05
2025-04-01 01:26:37 - train: epoch 169, iter:0, loss: 0.3286, lr: 1.992422146444796e-05
2025-04-01 01:27:53 - train: epoch 169, iter:64, loss: 0.3219, lr: 1.992422146444796e-05
2025-04-01 01:28:41 - train: epoch 170, iter:0, loss: 0.3533, lr: 2.7549856411061937e-05
2025-04-01 01:29:57 - train: epoch 170, iter:64, loss: 0.3269, lr: 2.7549856411061937e-05
2025-04-01 01:30:47 - train: epoch 171, iter:0, loss: 0.3783, lr: 3.723531507954293e-05
2025-04-01 01:32:02 - train: epoch 171, iter:64, loss: 0.3269, lr: 3.723531507954293e-05
2025-04-01 01:32:49 - train: epoch 172, iter:0, loss: 0.4228, lr: 4.889288445635957e-05
2025-04-01 01:34:05 - train: epoch 172, iter:64, loss: 0.3093, lr: 4.889288445635957e-05
2025-04-01 01:34:58 - train: epoch 173, iter:0, loss: 0.2715, lr: 6.241699178801576e-05
2025-04-01 01:36:14 - train: epoch 173, iter:64, loss: 0.3286, lr: 6.241699178801576e-05
2025-04-01 01:37:03 - train: epoch 174, iter:0, loss: 0.3363, lr: 7.768516066425623e-05
2025-04-01 01:38:18 - train: epoch 174, iter:64, loss: 0.3223, lr: 7.768516066425623e-05
2025-04-01 01:39:09 - train: epoch 175, iter:0, loss: 0.2654, lr: 9.455912018340265e-05
2025-04-01 01:40:24 - train: epoch 175, iter:64, loss: 0.3179, lr: 9.455912018340265e-05
2025-04-01 01:41:12 - train: epoch 176, iter:0, loss: 0.4219, lr: 0.00011288605715505355
2025-04-01 01:42:28 - train: epoch 176, iter:64, loss: 0.3201, lr: 0.00011288605715505355
2025-04-01 01:43:16 - train: epoch 177, iter:0, loss: 0.2831, lr: 0.00013249999999999674
2025-04-01 01:44:32 - train: epoch 177, iter:64, loss: 0.3120, lr: 0.00013249999999999674
2025-04-01 01:45:20 - train: epoch 178, iter:0, loss: 0.2714, lr: 0.00015322332181453497
2025-04-01 01:46:36 - train: epoch 178, iter:64, loss: 0.3337, lr: 0.00015322332181453497
2025-04-01 01:47:24 - train: epoch 179, iter:0, loss: 0.3365, lr: 0.00017486834898722766
2025-04-01 01:48:40 - train: epoch 179, iter:64, loss: 0.3389, lr: 0.00017486834898722766
2025-04-01 01:49:28 - train: epoch 180, iter:0, loss: 0.2866, lr: 0.0001972390608001859
2025-04-01 01:50:43 - train: epoch 180, iter:64, loss: 0.3464, lr: 0.0001972390608001859
2025-04-01 01:51:34 - train: epoch 181, iter:0, loss: 0.2997, lr: 0.0002201328646230403
2025-04-01 01:52:49 - train: epoch 181, iter:64, loss: 0.3385, lr: 0.0002201328646230403
2025-04-01 01:53:38 - train: epoch 182, iter:0, loss: 0.2634, lr: 0.0002433424306231779
2025-04-01 01:54:54 - train: epoch 182, iter:64, loss: 0.3546, lr: 0.0002433424306231779
2025-04-01 01:55:42 - train: epoch 183, iter:0, loss: 0.3306, lr: 0.00026665756937681035
2025-04-01 01:56:58 - train: epoch 183, iter:64, loss: 0.3559, lr: 0.00026665756937681035
2025-04-01 01:57:48 - train: epoch 184, iter:0, loss: 0.3393, lr: 0.00028986713537694795
2025-04-01 01:59:03 - train: epoch 184, iter:64, loss: 0.3522, lr: 0.00028986713537694795
2025-04-01 01:59:52 - train: epoch 185, iter:0, loss: 0.3283, lr: 0.0003127609391998024
2025-04-01 02:01:08 - train: epoch 185, iter:64, loss: 0.3521, lr: 0.0003127609391998024
2025-04-01 02:01:57 - train: epoch 186, iter:0, loss: 0.3794, lr: 0.0003351316510127607
2025-04-01 02:03:13 - train: epoch 186, iter:64, loss: 0.3736, lr: 0.0003351316510127607
2025-04-01 02:04:00 - train: epoch 187, iter:0, loss: 0.3380, lr: 0.0003567766781854534
2025-04-01 02:05:16 - train: epoch 187, iter:64, loss: 0.3712, lr: 0.0003567766781854534
2025-04-01 02:06:05 - train: epoch 188, iter:0, loss: 0.5177, lr: 0.0003774999999999916
2025-04-01 02:07:21 - train: epoch 188, iter:64, loss: 0.3712, lr: 0.0003774999999999916
2025-04-01 02:08:08 - train: epoch 189, iter:0, loss: 0.3918, lr: 0.0003971139428449348
2025-04-01 02:09:24 - train: epoch 189, iter:64, loss: 0.3805, lr: 0.0003971139428449348
2025-04-01 02:10:11 - train: epoch 190, iter:0, loss: 0.4379, lr: 0.0004154408798165857
2025-04-01 02:11:27 - train: epoch 190, iter:64, loss: 0.3887, lr: 0.0004154408798165857
2025-04-01 02:12:14 - train: epoch 191, iter:0, loss: 0.4173, lr: 0.00043231483933573215
2025-04-01 02:13:30 - train: epoch 191, iter:64, loss: 0.3723, lr: 0.00043231483933573215
2025-04-01 02:14:20 - train: epoch 192, iter:0, loss: 0.3851, lr: 0.0004475830082119726
2025-04-01 02:15:36 - train: epoch 192, iter:64, loss: 0.3915, lr: 0.0004475830082119726
2025-04-01 02:16:25 - train: epoch 193, iter:0, loss: 0.3724, lr: 0.0004611071155436288
2025-04-01 02:17:41 - train: epoch 193, iter:64, loss: 0.3797, lr: 0.0004611071155436288
2025-04-01 02:18:31 - train: epoch 194, iter:0, loss: 0.3786, lr: 0.0004727646849204454
2025-04-01 02:19:46 - train: epoch 194, iter:64, loss: 0.3761, lr: 0.0004727646849204454
2025-04-01 02:20:33 - train: epoch 195, iter:0, loss: 0.3967, lr: 0.0004824501435889265
2025-04-01 02:21:49 - train: epoch 195, iter:64, loss: 0.3872, lr: 0.0004824501435889265
2025-04-01 02:22:35 - train: epoch 196, iter:0, loss: 0.3583, lr: 0.0004900757785355405
2025-04-01 02:23:51 - train: epoch 196, iter:64, loss: 0.4087, lr: 0.0004900757785355405
2025-04-01 02:24:43 - train: epoch 197, iter:0, loss: 0.3841, lr: 0.0004955725308293517
2025-04-01 02:25:58 - train: epoch 197, iter:64, loss: 0.3967, lr: 0.0004955725308293517
2025-04-01 02:26:45 - train: epoch 198, iter:0, loss: 0.3164, lr: 0.0004988906210303943
2025-04-01 02:28:01 - train: epoch 198, iter:64, loss: 0.3996, lr: 0.0004988906210303943
2025-04-01 02:28:48 - train: epoch 199, iter:0, loss: 0.4178, lr: 0.0004999999999999885
2025-04-01 02:30:03 - train: epoch 199, iter:64, loss: 0.3950, lr: 0.0004999999999999885
2025-04-01 02:30:54 - train: epoch 200, iter:0, loss: 0.3178, lr: 0.0004988906210303943
2025-04-01 02:32:09 - train: epoch 200, iter:64, loss: 0.3885, lr: 0.0004988906210303943
2025-04-01 07:34:46 - #----------Config info----------#
2025-04-01 07:34:46 - network: 3munet,
2025-04-01 07:34:46 - model_config: {'num_classes': 7, 'input_channels': 3, 'depths': [2, 2, 2, 2, 2], 'depths_decoder': [2, 2, 2, 2, 1], 'drop_path_rate': 0.2, 'load_ckpt_path': './pre_trained_weights/vmamba_small_e238_ema.pth'},
2025-04-01 07:34:46 - start_epoch_best_model_saving: 0,
2025-04-01 07:34:46 - condition_hd95: 9.0,
2025-04-01 07:34:46 - deep_supervision: False,
2025-04-01 07:34:46 - deep_supervision_weight: [1.0, 1.0, 1.0, 1.0, 1.0],
2025-04-01 07:34:46 - mask_update: False,
2025-04-01 07:34:46 - mfe_enable: True,
2025-04-01 07:34:46 - mcsa_enable: True,
2025-04-01 07:34:46 - datasets: vofo,
2025-04-01 07:34:46 - data_path: ./data/vofo/,
2025-04-01 07:34:46 - pretrained_path: ./pre_trained/,
2025-04-01 07:34:46 - num_classes: 7,
2025-04-01 07:34:46 - color_palette: {0: [0, 0, 0], 1: [255, 0, 0], 2: [255, 165, 0], 3: [255, 255, 0], 4: [0, 255, 0], 5: [0, 0, 255], 6: [148, 0, 211]},
2025-04-01 07:34:46 - opacity: 0.7,
2025-04-01 07:34:46 - input_size_h: 256,
2025-04-01 07:34:46 - input_size_w: 256,
2025-04-01 07:34:46 - input_channels: 3,
2025-04-01 07:34:46 - distributed: False,
2025-04-01 07:34:46 - local_rank: -1,
2025-04-01 07:34:46 - num_workers: 16,
2025-04-01 07:34:46 - seed: 42,
2025-04-01 07:34:46 - world_size: None,
2025-04-01 07:34:46 - rank: None,
2025-04-01 07:34:46 - amp: False,
2025-04-01 07:34:46 - gpu_id: 0,
2025-04-01 07:34:46 - batch_size: 16,
2025-04-01 07:34:46 - epochs: 200,
2025-04-01 07:34:46 - loss_weight: [1, 1],
2025-04-01 07:34:46 - criterion: CeDiceLoss(
  (celoss): CrossEntropyLoss()
  (diceloss): nDiceLoss()
),
2025-04-01 07:34:46 - work_dir: ./results_vofo/,
2025-04-01 07:34:46 - print_interval: 64,
2025-04-01 07:34:46 - val_interval: 30,
2025-04-01 07:34:46 - save_interval: 100,
2025-04-01 07:34:46 - threshold: 0.5,
2025-04-01 07:34:46 - train_transformer: Compose(
    <utils.myNormalize object at 0x7f5532b51490>
    <utils.myToTensor object at 0x7f5532b514f0>
    <utils.myRandomHorizontalFlip object at 0x7f5532b51520>
    <utils.myRandomVerticalFlip object at 0x7f5532b51580>
    <utils.myRandomRotation object at 0x7f5532b515e0>
    <utils.myResize object at 0x7f5532b51640>
),
2025-04-01 07:34:46 - test_transformer: Compose(
    <utils.myNormalize object at 0x7f5532b51730>
    <utils.myToTensor object at 0x7f5532b51790>
    <utils.myResize object at 0x7f5532b517c0>
),
2025-04-01 07:34:46 - opt: AdamW,
2025-04-01 07:34:46 - lr: 0.0005,
2025-04-01 07:34:46 - betas: (0.9, 0.999),
2025-04-01 07:34:46 - eps: 1e-08,
2025-04-01 07:34:46 - weight_decay: 0.01,
2025-04-01 07:34:46 - amsgrad: False,
2025-04-01 07:34:46 - sch: CosineAnnealingLR,
2025-04-01 07:34:46 - T_max: 33,
2025-04-01 07:34:46 - eta_min: 1e-05,
2025-04-01 07:34:46 - last_epoch: -1,
2025-04-01 07:34:50 - flops: 3.921238656, params: 22.077297, Total params: : 27.9154
